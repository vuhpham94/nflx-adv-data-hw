{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optimizing Spark Skill Drill_UnSolved",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vuhpham94/nflx-adv-data-hw/blob/main/11192021/03-SkillDrill/Solved/Optimizing_Spark_Skill_Drill-VP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kcbx0f2q27rD"
      },
      "source": [
        " # Skill Drill: Putting it ALL together\n",
        " ## Overview\n",
        "\n",
        " A VP at your company has written a SQL for a report that shows how much time is being lost due to flight delays by Airport and Carrier.  It is performing below expectations.  Using all of the optimizing skills you have learned in Unit 8, get this query to run as fast as possible.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Hint: Initial query takes between 15-20 seconds.  Final query should be <2 seconds\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGA5-htN6oEN",
        "outputId": "7261e86b-ef66-4b64-a051-85616ef72c85"
      },
      "source": [
        "import os\n",
        "# Find the latest version of spark 3.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
        "# For example:\n",
        "# spark_version = 'spark-3.0.1'\n",
        "spark_version = 'spark-3.0.1'\n",
        "os.environ['SPARK_VERSION']=spark_version\n",
        "\n",
        "# Install Spark and Java\n",
        "!apt-get update\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "# Set Environment Variables\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
        "\n",
        "# Start a SparkSession\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connecting to cloud.r-project.o\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Waiting for headers] [2 InRelease 14.2 kB/88.7 kB 16%] [Connecting to cloud\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [2 InRelease 88.7 kB/88.7 kB 100%] [Connecting to cloud.r-project.org] [1 In\r                                                                               \rGet:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rHit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\r                                                                               \rGet:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (18.66.180.59)] [6 I\r                                                                               \rGet:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "\r0% [3 InRelease gpgv 242 kB] [Connected to cloud.r-project.org (18.66.180.59)] \r0% [3 InRelease gpgv 242 kB] [Connected to cloud.r-project.org (18.66.180.59)] \r                                                                               \rHit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:9 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [34.4 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [699 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,220 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,867 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [666 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,439 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [26.8 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,430 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,812 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [928 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.9 kB]\n",
            "Get:26 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [73.0 kB]\n",
            "Get:28 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [808 kB]\n",
            "Fetched 14.3 MB in 5s (2,957 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIUo9MYO6vlj"
      },
      "source": [
        "#import packages\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import Row\n",
        "from pyspark.sql.types import StructType,StructField,StringType, DateType,IntegerType\n",
        "import pandas as pd\n",
        "\n",
        "# we are going to use this to time our queries.\n",
        "import time\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej6Sabcd-1At"
      },
      "source": [
        "# Read in data from S3 Bucket\n",
        "from pyspark import SparkFiles\n",
        "url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-netflix/DelayedFlights.csv\"\n",
        "spark.sparkContext.addFile(url)\n",
        "df = spark.read.csv(SparkFiles.get(\"DelayedFlights.csv\"), sep=\",\", header=True)\n",
        "url_cities='https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-netflix/cities500.txt'\n",
        "spark.sparkContext.addFile(url_cities)\n",
        "df_lookup_geo = spark.read.csv(SparkFiles.get(\"cities500.txt\"), sep=\"\\t\", header=True)\n",
        "\n",
        "# we are going to do a lookup here as well so upload the airportCodes.csv file from you Resources directory \n",
        "#df_lookup_city_name=spark.read.csv('/content/airportCodes.csv', sep=',', header=True)\n",
        "url_airportcodes = 'https://raw.githubusercontent.com/vuhpham94/nflx-adv-data-hw/main/11192021/03-SkillDrill/Resources/airportCodes.csv'\n",
        "spark.sparkContext.addFile(url_airportcodes)\n",
        "df_lookup_city_name = spark.read.csv(SparkFiles.get(\"airportCodes.csv\"), sep=',', header=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DFhjm5Z_O5Z"
      },
      "source": [
        "#Create temporary views for each of our dataframes\n",
        "# We are going to filter the data to US only as we create the Temp Views.\n",
        "df.createOrReplaceTempView('delayed')\n",
        "df_lookup_city_name.createOrReplaceTempView('lookup_city')\n",
        "df_lookup_geo.createOrReplaceTempView('lookup_geo')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhgb2iFihRbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bf4a7d4-3f9b-4f0d-99dc-3597564bb588"
      },
      "source": [
        "# Here is the  initial query presented to you for optimization\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "with allColumns\n",
        "(select \n",
        "a.Year,\n",
        "a.Month,\n",
        "a.DayofMonth,\n",
        "a.DayOfWeek,\n",
        "a.DepTime,\n",
        "a.CRSDepTime,\n",
        "a.ArrTime,\n",
        "a.CRSArrTime,\n",
        "a.UniqueCarrier,\n",
        "a.FlightNum,\n",
        "a.TailNum,\n",
        "a.ActualElapsedTime,\n",
        "a.CRSElapsedTime,\n",
        "a.AirTime,\n",
        "a.ArrDelay,\n",
        "a.DepDelay,\n",
        "a.Origin,\n",
        "b.City as Origin_City,\n",
        "geo.latitude as Origin_latitude,\n",
        "geo.longitude as Origin_longitude,\n",
        "a.Dest,\n",
        "c.City as Dest_City,\n",
        "geo_dest.latitude as Dest_latitude,\n",
        "geo_dest.longitude as Dest_longitude,\n",
        "a.Distance,\n",
        "a.TaxiIn,\n",
        "a.TaxiOut,\n",
        "a.Cancelled,\n",
        "a.CancellationCode,\n",
        "a.Diverted,\n",
        "a.CarrierDelay,\n",
        "a.WeatherDelay,\n",
        "a.NASDelay,\n",
        "a.SecurityDelay,\n",
        "a.LateAircraftDelay from  delayed a \n",
        "  inner join lookup_city b\n",
        "    on a.Origin=b.airportCode\n",
        "  inner join lookup_city c\n",
        "    on a.Dest=c.airportCode\n",
        "  inner join lookup_geo geo\n",
        "on split(b.City,',')[0]=geo.name\n",
        "     and trim(split(b.City,',')[1])=geo.admin1_code\n",
        "  inner join lookup_geo geo_dest\n",
        "    on c.City=concat(geo_dest.name,', ',geo_dest.admin1_code)\n",
        ")\n",
        "select Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude, max(DepDelay) as delayed, avg(CarrierDelay) avgCarrierDelay \n",
        "from allColumns \n",
        "group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|Origin|UniqueCarrier|    Origin_City|Origin_latitude|Origin_Longitude|Dest_latitude|Dest_longitude|delayed|   avgCarrierDelay|\n",
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|   ATL|           EV|    Atlanta, GA|         33.749|       -84.38798|     31.31129|     -92.44514|   99.0| 28.81025641025641|\n",
            "|   ABQ|           DL|Albuquerque, NM|       35.08449|      -106.65114|       33.749|     -84.38798|   99.0|40.401869158878505|\n",
            "|   ATW|           EV|   Appleton, WI|       44.26193|       -88.41538|       33.749|     -84.38798|   99.0|30.546666666666667|\n",
            "|   BWI|           WN|  Baltimore, MD|       39.29038|       -76.61219|     30.26715|     -97.74306|   95.0|12.741935483870968|\n",
            "|   CAK|           EV|      Akron, OH|       41.08144|       -81.51901|       33.749|     -84.38798|   99.0|28.156941649899398|\n",
            "|   ATL|           OH|    Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|   97.0| 40.42245989304813|\n",
            "|   CAK|           FL|      Akron, OH|       41.08144|       -81.51901|     42.35843|     -71.05977|   99.0|  2.63302752293578|\n",
            "|   AEX|           EV| Alexandria, LA|       31.31129|       -92.44514|       33.749|     -84.38798|   96.0|27.155778894472363|\n",
            "|   BMI|           FL|Bloomington, IL|        40.4842|       -88.99369|       33.749|     -84.38798|   98.0| 8.437158469945356|\n",
            "|   BOS|           OH|     Boston, MA|       42.35843|       -71.05977|     44.80118|     -68.77781|   95.0|18.462311557788944|\n",
            "|   ATL|           EV|    Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 30.99437148217636|\n",
            "|   CAK|           DL|      Akron, OH|       41.08144|       -81.51901|       33.749|     -84.38798|    9.0| 27.91304347826087|\n",
            "|   ATL|           FL|    Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 12.44890510948905|\n",
            "|   BOS|           FL|     Boston, MA|       42.35843|       -71.05977|     41.08144|     -81.51901|   99.0|1.0092592592592593|\n",
            "|   BHM|           EV| Birmingham, AL|       33.52066|       -86.80249|       33.749|     -84.38798|   96.0| 17.04794520547945|\n",
            "|   ATL|           DL|    Atlanta, GA|         33.749|       -84.38798|     35.08449|    -106.65114|   98.0|20.948275862068964|\n",
            "|   BRW|           AS|     Barrow, AK|       71.29058|      -156.78872|     61.21806|    -149.90028|   97.0| 4.483516483516484|\n",
            "|   ATL|           OO|    Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|    6.0|              19.0|\n",
            "|   ASE|           OO|      Aspen, CO|        39.1911|      -106.81754|       33.749|     -84.38798|   82.0|               6.0|\n",
            "|   BWI|           EV|  Baltimore, MD|       39.29038|       -76.61219|       33.749|     -84.38798|   93.0|              15.5|\n",
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 17.377501249313354 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_797bPxUaFOY"
      },
      "source": [
        "#partition the largest table\n",
        "df.write.parquet('parquet_delayed', mode='overwrite')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R7wBwdVbk-f"
      },
      "source": [
        "# read the new parquet formatted data\n",
        "p_df=spark.read.parquet('parquet_delayed')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oWokIp2b0Ba"
      },
      "source": [
        "# create a view (same name as before so we don't have change our SQL)\n",
        "p_df.createOrReplaceTempView('delayed')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc4uyu-sb8zY",
        "outputId": "e7280acc-9ba7-46c3-d2e4-1968e363e8a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# run 2 after storing the data more appropriately and partitioning\n",
        "\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "with allColumns\n",
        "(select \n",
        "a.Year,\n",
        "a.Month,\n",
        "a.DayofMonth,\n",
        "a.DayOfWeek,\n",
        "a.DepTime,\n",
        "a.CRSDepTime,\n",
        "a.ArrTime,\n",
        "a.CRSArrTime,\n",
        "a.UniqueCarrier,\n",
        "a.FlightNum,\n",
        "a.TailNum,\n",
        "a.ActualElapsedTime,\n",
        "a.CRSElapsedTime,\n",
        "a.AirTime,\n",
        "a.ArrDelay,\n",
        "a.DepDelay,\n",
        "a.Origin,\n",
        "b.City as Origin_City,\n",
        "geo.latitude as Origin_latitude,\n",
        "geo.longitude as Origin_longitude,\n",
        "a.Dest,\n",
        "c.City as Dest_City,\n",
        "geo_dest.latitude as Dest_latitude,\n",
        "geo_dest.longitude as Dest_longitude,\n",
        "a.Distance,\n",
        "a.TaxiIn,\n",
        "a.TaxiOut,\n",
        "a.Cancelled,\n",
        "a.CancellationCode,\n",
        "a.Diverted,\n",
        "a.CarrierDelay,\n",
        "a.WeatherDelay,\n",
        "a.NASDelay,\n",
        "a.SecurityDelay,\n",
        "a.LateAircraftDelay from  delayed a \n",
        "  inner join lookup_city b\n",
        "    on a.Origin=b.airportCode\n",
        "  inner join lookup_city c\n",
        "    on a.Dest=c.airportCode\n",
        "  inner join lookup_geo geo\n",
        "on split(b.City,',')[0]=geo.name\n",
        "     and trim(split(b.City,',')[1])=geo.admin1_code\n",
        "  inner join lookup_geo geo_dest\n",
        "    on c.City=concat(geo_dest.name,', ',geo_dest.admin1_code)\n",
        ")\n",
        "select Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude, max(DepDelay) as delayed, avg(CarrierDelay) avgCarrierDelay \n",
        "from allColumns \n",
        "group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|Origin|UniqueCarrier|    Origin_City|Origin_latitude|Origin_Longitude|Dest_latitude|Dest_longitude|delayed|   avgCarrierDelay|\n",
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|   ATL|           EV|    Atlanta, GA|         33.749|       -84.38798|     31.31129|     -92.44514|   99.0| 28.81025641025641|\n",
            "|   ABQ|           DL|Albuquerque, NM|       35.08449|      -106.65114|       33.749|     -84.38798|   99.0|40.401869158878505|\n",
            "|   ATW|           EV|   Appleton, WI|       44.26193|       -88.41538|       33.749|     -84.38798|   99.0|30.546666666666667|\n",
            "|   BWI|           WN|  Baltimore, MD|       39.29038|       -76.61219|     30.26715|     -97.74306|   95.0|12.741935483870968|\n",
            "|   CAK|           EV|      Akron, OH|       41.08144|       -81.51901|       33.749|     -84.38798|   99.0|28.156941649899398|\n",
            "|   ATL|           OH|    Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|   97.0| 40.42245989304813|\n",
            "|   CAK|           FL|      Akron, OH|       41.08144|       -81.51901|     42.35843|     -71.05977|   99.0|  2.63302752293578|\n",
            "|   AEX|           EV| Alexandria, LA|       31.31129|       -92.44514|       33.749|     -84.38798|   96.0|27.155778894472363|\n",
            "|   BMI|           FL|Bloomington, IL|        40.4842|       -88.99369|       33.749|     -84.38798|   98.0| 8.437158469945356|\n",
            "|   BOS|           OH|     Boston, MA|       42.35843|       -71.05977|     44.80118|     -68.77781|   95.0|18.462311557788944|\n",
            "|   ATL|           EV|    Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 30.99437148217636|\n",
            "|   CAK|           DL|      Akron, OH|       41.08144|       -81.51901|       33.749|     -84.38798|    9.0| 27.91304347826087|\n",
            "|   ATL|           FL|    Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 12.44890510948905|\n",
            "|   BOS|           FL|     Boston, MA|       42.35843|       -71.05977|     41.08144|     -81.51901|   99.0|1.0092592592592593|\n",
            "|   BHM|           EV| Birmingham, AL|       33.52066|       -86.80249|       33.749|     -84.38798|   96.0| 17.04794520547945|\n",
            "|   ATL|           DL|    Atlanta, GA|         33.749|       -84.38798|     35.08449|    -106.65114|   98.0|20.948275862068964|\n",
            "|   BRW|           AS|     Barrow, AK|       71.29058|      -156.78872|     61.21806|    -149.90028|   97.0| 4.483516483516484|\n",
            "|   ATL|           OO|    Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|    6.0|              19.0|\n",
            "|   ASE|           OO|      Aspen, CO|        39.1911|      -106.81754|       33.749|     -84.38798|   82.0|               6.0|\n",
            "|   BWI|           EV|  Baltimore, MD|       39.29038|       -76.61219|       33.749|     -84.38798|   93.0|              15.5|\n",
            "+------+-------------+---------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 5.725757122039795 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f3iZbtlcMZ6"
      },
      "source": [
        "# Recall that the default shuffle partitions is 200.  We want to bring that down to a reasonable size for both our data and our Spark cluster\n",
        "# 4 is reasonable for a free Colab \n",
        "spark.conf.set(\"spark.sql.shuffle.partitions\", 4)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvYdTGRCcQjN",
        "outputId": "8c55e3d5-e6d3-4d77-dec0-0407ce1172b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Run 3 after setting the shuffle partitions to a more appropriate number\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "with allColumns\n",
        "(select \n",
        "a.Year,\n",
        "a.Month,\n",
        "a.DayofMonth,\n",
        "a.DayOfWeek,\n",
        "a.DepTime,\n",
        "a.CRSDepTime,\n",
        "a.ArrTime,\n",
        "a.CRSArrTime,\n",
        "a.UniqueCarrier,\n",
        "a.FlightNum,\n",
        "a.TailNum,\n",
        "a.ActualElapsedTime,\n",
        "a.CRSElapsedTime,\n",
        "a.AirTime,\n",
        "a.ArrDelay,\n",
        "a.DepDelay,\n",
        "a.Origin,\n",
        "b.City as Origin_City,\n",
        "geo.latitude as Origin_latitude,\n",
        "geo.longitude as Origin_longitude,\n",
        "a.Dest,\n",
        "c.City as Dest_City,\n",
        "geo_dest.latitude as Dest_latitude,\n",
        "geo_dest.longitude as Dest_longitude,\n",
        "a.Distance,\n",
        "a.TaxiIn,\n",
        "a.TaxiOut,\n",
        "a.Cancelled,\n",
        "a.CancellationCode,\n",
        "a.Diverted,\n",
        "a.CarrierDelay,\n",
        "a.WeatherDelay,\n",
        "a.NASDelay,\n",
        "a.SecurityDelay,\n",
        "a.LateAircraftDelay from  delayed a \n",
        "  inner join lookup_city b\n",
        "    on a.Origin=b.airportCode\n",
        "  inner join lookup_city c\n",
        "    on a.Dest=c.airportCode\n",
        "  inner join lookup_geo geo\n",
        "on split(b.City,',')[0]=geo.name\n",
        "     and trim(split(b.City,',')[1])=geo.admin1_code\n",
        "  inner join lookup_geo geo_dest\n",
        "    on c.City=concat(geo_dest.name,', ',geo_dest.admin1_code)\n",
        ")\n",
        "select Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude, max(DepDelay) as delayed, avg(CarrierDelay) avgCarrierDelay \n",
        "from allColumns \n",
        "group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|Origin|UniqueCarrier|  Origin_City|Origin_latitude|Origin_Longitude|Dest_latitude|Dest_longitude|delayed|   avgCarrierDelay|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|   ABE|           OO|Allentown, PA|       40.60843|       -75.49018|     33.52066|     -86.80249|   11.0|              null|\n",
            "|   ALB|           OH|   Albany, NY|       42.65258|       -73.75623|     42.35843|     -71.05977|   55.0|               0.0|\n",
            "|   ALB|           WN|   Albany, NY|       42.65258|       -73.75623|     39.29038|     -76.61219|   99.0| 8.203647416413373|\n",
            "|   ASE|           OO|    Aspen, CO|        39.1911|      -106.81754|       33.749|     -84.38798|   82.0|               6.0|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   94.0|15.083333333333334|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|    6.0|              null|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|   99.0| 20.12719298245614|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   98.0|            19.856|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|    7.0| 17.11111111111111|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     61.21806|    -149.90028|    9.0|             25.75|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|   82.0|              17.6|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.36415|     -74.42306|    9.0|  46.1578947368421|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 30.99437148217636|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     30.44332|     -91.18747|   82.0| 48.13333333333333|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     40.60843|     -75.49018|    8.0|              16.5|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   31.0|               0.0|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|      39.1911|    -106.81754|   81.0|13.571428571428571|\n",
            "|   ATW|           OH| Appleton, WI|       44.26193|       -88.41538|       33.749|     -84.38798|   70.0|             46.25|\n",
            "|   AUS|           DL|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   96.0| 22.71904761904762|\n",
            "|   AUS|           OH|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   90.0|             43.64|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 4.771872282028198 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPR_2uq0vdyt",
        "outputId": "25acc82b-4810-4fdc-8a27-ab361470b2d9"
      },
      "source": [
        "# cache your largest temporary view\n",
        "# Note: when we use SparkSQL to cache a table, the table is immediately cached (no lazy evaluation), when using Pyspark it will not be cached until an action is ran.\n",
        "spark.sql(\"cache table delayed\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eodqtIHByC2J",
        "outputId": "c03f6fea-bf10-4ae0-fda6-069f7f673dbe"
      },
      "source": [
        "# check that your table is cached \n",
        "spark.catalog.isCached(\"delayed\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP7129kUda1b",
        "outputId": "77d963a3-306e-40f5-f969-ab64e193f147",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Run 4 - after caching driver table\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "with allColumns\n",
        "(select \n",
        "a.Year,\n",
        "a.Month,\n",
        "a.DayofMonth,\n",
        "a.DayOfWeek,\n",
        "a.DepTime,\n",
        "a.CRSDepTime,\n",
        "a.ArrTime,\n",
        "a.CRSArrTime,\n",
        "a.UniqueCarrier,\n",
        "a.FlightNum,\n",
        "a.TailNum,\n",
        "a.ActualElapsedTime,\n",
        "a.CRSElapsedTime,\n",
        "a.AirTime,\n",
        "a.ArrDelay,\n",
        "a.DepDelay,\n",
        "a.Origin,\n",
        "b.City as Origin_City,\n",
        "geo.latitude as Origin_latitude,\n",
        "geo.longitude as Origin_longitude,\n",
        "a.Dest,\n",
        "c.City as Dest_City,\n",
        "geo_dest.latitude as Dest_latitude,\n",
        "geo_dest.longitude as Dest_longitude,\n",
        "a.Distance,\n",
        "a.TaxiIn,\n",
        "a.TaxiOut,\n",
        "a.Cancelled,\n",
        "a.CancellationCode,\n",
        "a.Diverted,\n",
        "a.CarrierDelay,\n",
        "a.WeatherDelay,\n",
        "a.NASDelay,\n",
        "a.SecurityDelay,\n",
        "a.LateAircraftDelay from  delayed a \n",
        "  inner join lookup_city b\n",
        "    on a.Origin=b.airportCode\n",
        "  inner join lookup_city c\n",
        "    on a.Dest=c.airportCode\n",
        "  inner join lookup_geo geo\n",
        "on split(b.City,',')[0]=geo.name\n",
        "     and trim(split(b.City,',')[1])=geo.admin1_code\n",
        "  inner join lookup_geo geo_dest\n",
        "    on c.City=concat(geo_dest.name,', ',geo_dest.admin1_code)\n",
        ")\n",
        "select Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude, max(DepDelay) as delayed, avg(CarrierDelay) avgCarrierDelay \n",
        "from allColumns \n",
        "group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|Origin|UniqueCarrier|  Origin_City|Origin_latitude|Origin_Longitude|Dest_latitude|Dest_longitude|delayed|   avgCarrierDelay|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|   ABE|           OO|Allentown, PA|       40.60843|       -75.49018|     33.52066|     -86.80249|   11.0|              null|\n",
            "|   ALB|           OH|   Albany, NY|       42.65258|       -73.75623|     42.35843|     -71.05977|   55.0|               0.0|\n",
            "|   ALB|           WN|   Albany, NY|       42.65258|       -73.75623|     39.29038|     -76.61219|   99.0| 8.203647416413373|\n",
            "|   ASE|           OO|    Aspen, CO|        39.1911|      -106.81754|       33.749|     -84.38798|   82.0|               6.0|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   94.0|15.083333333333334|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|    6.0|              null|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|   99.0| 20.12719298245614|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   98.0|            19.856|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|    7.0| 17.11111111111111|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     61.21806|    -149.90028|    9.0|             25.75|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|   82.0|              17.6|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.36415|     -74.42306|    9.0|  46.1578947368421|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 30.99437148217636|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     30.44332|     -91.18747|   82.0| 48.13333333333333|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     40.60843|     -75.49018|    8.0|              16.5|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   31.0|               0.0|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|      39.1911|    -106.81754|   81.0|13.571428571428571|\n",
            "|   ATW|           OH| Appleton, WI|       44.26193|       -88.41538|       33.749|     -84.38798|   70.0|             46.25|\n",
            "|   AUS|           DL|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   96.0| 22.71904761904762|\n",
            "|   AUS|           OH|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   90.0|             43.64|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 4.532657623291016 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfvIwCCChuvc",
        "outputId": "28995e2c-5e0e-4533-a0ed-52c4c5a3e65e"
      },
      "source": [
        "# you can even cache a large lookup table.\n",
        "spark.sql(\"cache table lookup_geo\")\n",
        "spark.catalog.isCached(\"lookup_geo\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RUF5D1GJOF3",
        "outputId": "863d710c-b07b-444f-e6cf-44659cf433e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spark.sql(\"cache table lookup_city\")\n",
        "spark.catalog.isCached(\"lookup_city\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31NhqcGgh7HG",
        "outputId": "5fec8f1f-1aaf-49a4-c222-8164789f1546",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Run 5 - caching one of the lookups\n",
        "#Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "with allColumns\n",
        "(select \n",
        "a.Year,\n",
        "a.Month,\n",
        "a.DayofMonth,\n",
        "a.DayOfWeek,\n",
        "a.DepTime,\n",
        "a.CRSDepTime,\n",
        "a.ArrTime,\n",
        "a.CRSArrTime,\n",
        "a.UniqueCarrier,\n",
        "a.FlightNum,\n",
        "a.TailNum,\n",
        "a.ActualElapsedTime,\n",
        "a.CRSElapsedTime,\n",
        "a.AirTime,\n",
        "a.ArrDelay,\n",
        "a.DepDelay,\n",
        "a.Origin,\n",
        "b.City as Origin_City,\n",
        "geo.latitude as Origin_latitude,\n",
        "geo.longitude as Origin_longitude,\n",
        "a.Dest,\n",
        "c.City as Dest_City,\n",
        "geo_dest.latitude as Dest_latitude,\n",
        "geo_dest.longitude as Dest_longitude,\n",
        "a.Distance,\n",
        "a.TaxiIn,\n",
        "a.TaxiOut,\n",
        "a.Cancelled,\n",
        "a.CancellationCode,\n",
        "a.Diverted,\n",
        "a.CarrierDelay,\n",
        "a.WeatherDelay,\n",
        "a.NASDelay,\n",
        "a.SecurityDelay,\n",
        "a.LateAircraftDelay from  delayed a \n",
        "  inner join lookup_city b\n",
        "    on a.Origin=b.airportCode\n",
        "  inner join lookup_city c\n",
        "    on a.Dest=c.airportCode\n",
        "  inner join lookup_geo geo\n",
        "on split(b.City,',')[0]=geo.name\n",
        "     and trim(split(b.City,',')[1])=geo.admin1_code\n",
        "  inner join lookup_geo geo_dest\n",
        "    on c.City=concat(geo_dest.name,', ',geo_dest.admin1_code)\n",
        ")\n",
        "select Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude, max(DepDelay) as delayed, avg(CarrierDelay) avgCarrierDelay \n",
        "from allColumns \n",
        "group by Origin, UniqueCarrier, Origin_City, Origin_latitude, Origin_Longitude, Dest_latitude, Dest_longitude\n",
        "\"\"\").show()\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|Origin|UniqueCarrier|  Origin_City|Origin_latitude|Origin_Longitude|Dest_latitude|Dest_longitude|delayed|   avgCarrierDelay|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "|   ABE|           OO|Allentown, PA|       40.60843|       -75.49018|     33.52066|     -86.80249|   11.0|              null|\n",
            "|   ALB|           OH|   Albany, NY|       42.65258|       -73.75623|     42.35843|     -71.05977|   55.0|               0.0|\n",
            "|   ALB|           WN|   Albany, NY|       42.65258|       -73.75623|     39.29038|     -76.61219|   99.0| 8.203647416413373|\n",
            "|   ASE|           OO|    Aspen, CO|        39.1911|      -106.81754|       33.749|     -84.38798|   82.0|               6.0|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   94.0|15.083333333333334|\n",
            "|   ATL|           9E|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|    6.0|              null|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     30.26715|     -97.74306|   99.0| 20.12719298245614|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   98.0|            19.856|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|    7.0| 17.11111111111111|\n",
            "|   ATL|           DL|  Atlanta, GA|         33.749|       -84.38798|     61.21806|    -149.90028|    9.0|             25.75|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.29038|     -76.61219|   82.0|              17.6|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     39.36415|     -74.42306|    9.0|  46.1578947368421|\n",
            "|   ATL|           EV|  Atlanta, GA|         33.749|       -84.38798|     41.08144|     -81.51901|   99.0| 30.99437148217636|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     30.44332|     -91.18747|   82.0| 48.13333333333333|\n",
            "|   ATL|           OH|  Atlanta, GA|         33.749|       -84.38798|     40.60843|     -75.49018|    8.0|              16.5|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|     33.52066|     -86.80249|   31.0|               0.0|\n",
            "|   ATL|           OO|  Atlanta, GA|         33.749|       -84.38798|      39.1911|    -106.81754|   81.0|13.571428571428571|\n",
            "|   ATW|           OH| Appleton, WI|       44.26193|       -88.41538|       33.749|     -84.38798|   70.0|             46.25|\n",
            "|   AUS|           DL|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   96.0| 22.71904761904762|\n",
            "|   AUS|           OH|   Austin, TX|       30.26715|       -97.74306|       33.749|     -84.38798|   90.0|             43.64|\n",
            "+------+-------------+-------------+---------------+----------------+-------------+--------------+-------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "--- 3.521435022354126 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDO8GpNZe7gc"
      },
      "source": [
        "# run 6 - remove unnecesary columns from the SQL\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "<put your sql here>\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl4WnpzdfZb4"
      },
      "source": [
        "# run 7 - filter the lookup tables in the SQL\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "< re-write your sql applying a filter to each lookup table>\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa1QQLnjKQEv",
        "outputId": "838f53fc-fffc-4e83-972d-90099835ab73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Remember to uncache the table as soon as you are done.\n",
        "spark.sql(\"uncache table delayed\")\n",
        "spark.sql(\"uncache table lookup_geo\")\n",
        "spark.sql(\"uncache table lookup_city\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy6F4EZ4gfSP"
      },
      "source": [
        "#recreate the dataframes selecting only the columns you need, filtering the data before creating the view, then caching the views.\n",
        "# columns needed are 'UniqueCarrier','DepDelay','Origin','CarrierDelay','Dest' from the main table\n",
        "<df.select here>\n",
        "# filter the df_lookup_city data prior to creating the view to only contain USA data\n",
        "\n",
        "# filter the df_lookup_geo data prior to creating the view to only contain US data and select only the columns you need to perform the lookup\n",
        "# fields from geo ('name','latitude','longitude','admin1_code')\n",
        "\n",
        "df_lookup_city_name.createOrReplaceTempView('lookup_city')\n",
        "df_lookup_geo.createOrReplaceTempView('lookup_geo')\n",
        "df.createOrReplaceTempView('delayed')\n",
        "spark.sql(\"cache table delayed\")\n",
        "spark.sql(\"cache table lookup_geo\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmk2rn5Zg-tC"
      },
      "source": [
        "# run 8 - filtered lookup dataframes\n",
        "# Note the runtime\n",
        "start_time = time.time()\n",
        "\n",
        "<final query should return the same data as the first query, but much faster>\n",
        "\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3P82CRVDxk7s"
      },
      "source": [
        "# Remember to uncache the table as soon as you are done.\n",
        "spark.sql(\"uncache table delayed\")\n",
        "spark.sql(\"uncache table lookup_geo\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHEPdkk_x0Ep"
      },
      "source": [
        "#Verify that the table is no longer cached\n",
        "if spark.catalog.isCached(\"delayed\") or spark.catalog.isCached(\"lookup_geo\"):\n",
        "  print(\"a table is till cached\")\n",
        "else:\n",
        "  print(\"all clear\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XLLlG2kx4s3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}